<html>

<head>
<title>Title</title>
</head>

<body>

<p>This is an R HTML document. When you click the <b>Knit HTML</b> button a web page will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:</p>

<!--begin.rcode
summary(cars)
end.rcode-->

<p>You can also embed plots, for example:</p>

<!--begin.rcode fig.width=7, fig.height=6
plot(cars)
end.rcode-->

</body>
</html>
> setwd("C:/Users/HECKERBELLA LIMITED/Downloads/machine learning")
> training <- read.csv("pml-training.csv", header=TRUE)
> testing <- read.csv("pml-testing.csv", header=TRUE)
> library(caret)
Loading required package: lattice
Loading required package: ggplot2
Warning messages:
1: package 'caret' was built under R version 3.4.4 
2: package 'lattice' was built under R version 3.4.4 
3: package 'ggplot2' was built under R version 3.4.4 
> ## Loading required package: lattice
> ## Loading required package: ggplot2
> library(randomForest)
randomForest 4.6-14
Type rfNews() to see new features/changes/bug fixes.

Attaching package: 'randomForest'

The following object is masked from 'package:ggplot2':

    margin

Warning message:
package 'randomForest' was built under R version 3.4.4 
> ## randomForest 4.6-10
> ## Type rfNews() to see new features/changes/bug fixes.
> library(plyr)
Warning message:
package 'plyr' was built under R version 3.4.4 
> options(warn=-1)
> Cleaning data
Error: unexpected symbol in "Cleaning data"
> #  Cleaning data
> # Removing the starting 6 columns from the training and testing datasets :
> #  'X',  'user_name', 'raw_timestamp_part_1', 'raw_timestamp_part_2', 'cvtd_timestamp', 'new_window'
> testing <- subset(testing, select=-c(1:7))
> training <- subset(training, select=-c(1:7))
> # Putting a Threshold value for the check on the number of occurences of 'NA' or '""' empty values in the datasets
> threshold_val <- 0.95 * dim(training)[1]
> # Here we will be removing the columns which are fully 'NA' or full empty or have more than 95 % NA or empty values, and include rest of the columns
> include_cols <- !apply(training, 2, function(y) sum(is.na(y)) > threshold_val || sum(y=="") > threshold_val)
> training <- training[, include_cols]
> #Further Cleaning of Data
> # Removing the columns which have very low variance values, and including the favourable ones
> nearZvar <- nearZeroVar(training, saveMetrics = TRUE)
> training <- training[ , nearZvar$nzv==FALSE] 
> dim(training)
[1] 19622    53
> # Making a correlation matrix to remove the columns which are highly correlated with each other
> # Putting a threshold value check here as well
> corr_matrix <- abs(cor(training[,-dim(training)[2]]))
> # Making the default diagonal values from '1' to '0', so that these values aren't included later 
> diag(corr_matrix) <- 0
> # Here we will be removing the columns which are highly correlated
> correlated_col <- findCorrelation(corr_matrix, verbose = FALSE , cutoff = .95)
> training <- training[, -c(correlated_col)]
> dim(training)
[1] 19622    49
> # This removed 4 columns out of the dataframe which were highly correlated
> #Modelling Data
> set.seed(32233)
> # Dividing the training dataset in 2 parts with p=0.7
> inTrain = createDataPartition(training$classe, p = 0.7, list=FALSE)
> train1A <- training[inTrain,]
> train2A <- training[-inTrain,]
> # While creating the model, we have to specify 'importance=TRUE' for further ease in Variable-Importance plot.
> # randForMod <- randomForest(classe~., data=train1A)
> randomForMod <- randomForest(classe~., data=train1A, importance=TRUE)
> randomForMod

Call:
 randomForest(formula = classe ~ ., data = train1A, importance = TRUE) 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 6

        OOB estimate of  error rate: 0.58%
Confusion matrix:
     A    B    C    D    E  class.error
A 3904    1    0    0    1 0.0005120328
B   14 2641    3    0    0 0.0063957863
C    0   18 2374    4    0 0.0091819699
D    0    0   30 2220    2 0.0142095915
E    0    0    2    5 2518 0.0027722772
> ## 
> ## Call:
> ##  randomForest(formula = classe ~ ., data = train1A, importance = TRUE) 
> ##                Type of random forest: classification
> ##                      Number of trees: 500
> ## No. of variables tried at each split: 6
> ## 
> ##         OOB estimate of  error rate: 0.54%
> ## Confusion matrix:
> ##      A    B    C    D    E class.error
> ## A 3903    1    1    0    1    0.000768
> ## B   12 2642    4    0    0    0.006020
> ## C    0   19 2374    3    0    0.009182
> ## D    0    0   25 2225    2    0.011989
> ## E    0    0    3    3 2519    0.002376
> # This takes a lot of time, and gives accuracy around 96%
> # ranFMod <- train(classe~., data=train2A, method="rf")
> 
> 
> # Testing the above model on train2A  dataset of the training dataset
> train2A_pred <- predict(randomForMod, newdata=train2A)
> # Showing the Confusion Matrix here :
> confusionMatrix(train2A_pred, train2A$classe)
Error: package e1071 is required
> install.packages("e1071")
Installing package into 'C:/Users/HECKERBELLA LIMITED/Documents/R/win-library/3.4'
(as 'lib' is unspecified)
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/e1071_1.7-1.zip'
Content type 'application/zip' length 896586 bytes (875 KB)
downloaded 875 KB

package 'e1071' successfully unpacked and MD5 sums checked

The downloaded binary packages are in
	C:\Users\HECKERBELLA LIMITED\AppData\Local\Temp\Rtmp8GNXBe\downloaded_packages
> confusionMatrix(train2A_pred, train2A$classe)
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1674    3    0    0    0
         B    0 1135    6    0    0
         C    0    1 1020    5    1
         D    0    0    0  958    4
         E    0    0    0    1 1077

Overall Statistics
                                          
               Accuracy : 0.9964          
                 95% CI : (0.9946, 0.9978)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9955          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            1.0000   0.9965   0.9942   0.9938   0.9954
Specificity            0.9993   0.9987   0.9986   0.9992   0.9998
Pos Pred Value         0.9982   0.9947   0.9932   0.9958   0.9991
Neg Pred Value         1.0000   0.9992   0.9988   0.9988   0.9990
Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
Detection Rate         0.2845   0.1929   0.1733   0.1628   0.1830
Detection Prevalence   0.2850   0.1939   0.1745   0.1635   0.1832
Balanced Accuracy      0.9996   0.9976   0.9964   0.9965   0.9976
> ## Confusion Matrix and Statistics
> ## 
> ##           Reference
> ## Prediction    A    B    C    D    E
> ##          A 1674    4    0    0    0
> ##          B    0 1135    4    0    0
> ##          C    0    0 1022    6    2
> ##          D    0    0    0  957    4
> ##          E    0    0    0    1 1076
> ## 
> ## Overall Statistics
> ##                                         
> ##                Accuracy : 0.996         
> ##                  95% CI : (0.995, 0.998)
> ##     No Information Rate : 0.284         
> ##     P-Value [Acc > NIR] : <2e-16        
> ##                                         
> ##                   Kappa : 0.995         
> ##  Mcnemar's Test P-Value : NA            
> ## 
> ## Statistics by Class:
> ## 
> ##                      Class: A Class: B Class: C Class: D Class: E
> ## Sensitivity             1.000    0.996    0.996    0.993    0.994
> ## Specificity             0.999    0.999    0.998    0.999    1.000
> ## Pos Pred Value          0.998    0.996    0.992    0.996    0.999
> ## Neg Pred Value          1.000    0.999    0.999    0.999    0.999
> ## Prevalence              0.284    0.194    0.174    0.164    0.184
> ## Detection Rate          0.284    0.193    0.174    0.163    0.183
> ## Detection Prevalence    0.285    0.194    0.175    0.163    0.183
> ## Balanced Accuracy       1.000    0.998    0.997    0.996    0.997
> #The Confusion Matrix achieved 99.59% accuracy. Here, the Out-Of-Sample Error Rate observed is 0.41%, and the OOB (Out-Of-Bag) Error Rate is 0.63%.
> #Checking Out-of-Sample-Error
> # On the basis of the Confusion Matrix calculated above, showing the the out-of-sample error value:
> confM <- confusionMatrix(train2A_pred, train2A$classe)
> sum(diag(confM$table))/sum(confM$table)
[1] 0.9964316
> # Variable-Importance Plot
> # Calculating the important predictors of the randomForest model via 'varImp()' function.
> # Performing the variable importance evaluation function using the above randomForest model:
> # Using 'scale=FALSE' to avoid the automatic normalization done by the varImp() function
> # rfImp <- varImp(randForMod, scale=FALSE) 
> randomfImp <- varImp(randomForMod, scale=FALSE) 
> # This gives the plot for the top 25 important variables
> varImpPlot(randomForMod, top=25, main="Top 25 Variable Importance")
> # Model on 'testing dataset'
> #These are the solutions for the 20 cases which have been submitted as the answers.
> # Testing the model on the 'testing' dataset
> testing_pred <- predict(randomForMod, newdata=testing)
> testing_pred
 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
 B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
Levels: A B C D E
> pml_write_files = function(x){
+     n = length(x)
+     for(i in 1:n){
+         filename = paste0("problem_id_",i,".txt")
+         write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
+     }
+ }
> 
> #pml_write_files(as.character(testing_pred))
> 
